{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T01:59:38.071218Z",
     "start_time": "2020-07-29T01:59:37.461543Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:00:03.652558Z",
     "start_time": "2020-07-29T01:59:47.957409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 540kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 85.5kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 119kB/s] \n"
     ]
    }
   ],
   "source": [
    "spacyGer = spacy.load('de')\n",
    "spacyEng = spacy.load('en')\n",
    "\n",
    "def tokenizerGer(text):\n",
    "    return [tok.text for tok in spacyGer.tokenizer(text)]\n",
    "def tokenizerEng(text):\n",
    "    return [tok.text for tok in spacyEng.tokenizer(text)]\n",
    "\n",
    "german = Field(tokenize=tokenizerGer, lower=True, init_token='<sos>', eos_token='<eos>')\n",
    "english = Field(tokenize=tokenizerEng, lower=True, init_token='<sos>', eos_token='<eos>')\n",
    "\n",
    "trainData, validationData, testData = Multi30k.splits(exts=('.de', '.en'),\n",
    "                                                     fields=(german, english))\n",
    "\n",
    "german.build_vocab(trainData, max_size=10000, min_freq=2)\n",
    "english.build_vocab(trainData, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:30:12.397592Z",
     "start_time": "2020-07-29T02:30:12.378254Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, inputSize, embeddingSize, hiddenSize, numLayers, p):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(inputSize, embeddingSize)\n",
    "        self.lstm = nn.LSTM(embeddingSize, hiddenSize, numLayers, dropout=p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape : (seq length, batch size)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape : (seq length, batch size, embedding size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(embedding)\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:52.730427Z",
     "start_time": "2020-07-29T02:32:52.725101Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, inputSize, embeddingSize, hiddenSize, outputSize, numLayers, p):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hiddenSize = hiddenSize\n",
    "        self.numLayers = numLayers\n",
    "        \n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.embedding = nn.Embedding(inputSize, embeddingSize)\n",
    "        self.lstm = nn.LSTM(embeddingSize, hiddenSize, numLayers, dropout=p)\n",
    "        self.fc = nn.Linear(hiddenSize, outputSize)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        # x shape : (batch size) -> (1,batch size)\n",
    "        x = x.unsqueeze(0)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        # embedding shape : (1, batch size, embedding size)\n",
    "        \n",
    "        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n",
    "        # outputs shape : (1, batch size, hidden size)\n",
    "        \n",
    "        predictions = self.fc(outputs)\n",
    "        # predictions shape : (1, batch size, length of target vocab)\n",
    "        \n",
    "        predictions = predictions.squeeze(0)\n",
    "        \n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:53.176701Z",
     "start_time": "2020-07-29T02:32:53.156795Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, source, target, teacherForceRatio=0.5):\n",
    "        batchSize = source.shape[1]\n",
    "        targetLen = target.shape[0]\n",
    "        targetVocabSize = len(english.vocab)\n",
    "        \n",
    "        outputs = torch.zeros(targetLen, batchSize, targetVocabSize).to(device)\n",
    "        \n",
    "        hidden, cell = self.encoder(source)\n",
    "        \n",
    "        # start token\n",
    "        x = target[0]\n",
    "        \n",
    "        for t in range(1, targetLen):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            bestGuess = output.argmax(1)  \n",
    "            x = target[t] if random.random() < teacherForceRatio else bestGuess\n",
    "            \n",
    "        return outputs       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:54.080474Z",
     "start_time": "2020-07-29T02:32:54.078332Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "numEpochs = 20\n",
    "learningRate  = 0.001\n",
    "batchSize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:54.508975Z",
     "start_time": "2020-07-29T02:32:54.497177Z"
    }
   },
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "loadModel = False\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "inputSizeEncoder = len(german.vocab)\n",
    "inputSizeDecoder = len(english.vocab)\n",
    "outputSize = len(english.vocab)\n",
    "encoderEmbeddingSize = 300\n",
    "decoderEmbeddingSize = 300\n",
    "hiddenSize = 1024\n",
    "numLayers = 2\n",
    "encoderDropout = 0.5\n",
    "decoderDropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:55.074491Z",
     "start_time": "2020-07-29T02:32:54.860944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "writer = SummaryWriter(f'runs/lossPlot')\n",
    "step = 0\n",
    "\n",
    "trainIterator, valIterator, testIterator = BucketIterator.splits(\n",
    "    (trainData, validationData, testData),\n",
    "    batch_size=batchSize,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device)\n",
    "\n",
    "encoderNet = Encoder(inputSizeEncoder, encoderEmbeddingSize,\n",
    "                    hiddenSize, numLayers, encoderDropout).to(device)\n",
    "\n",
    "\n",
    "decoderNet = Decoder(inputSizeDecoder, decoderEmbeddingSize,\n",
    "                    hiddenSize, outputSize, numLayers, decoderDropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:55.367674Z",
     "start_time": "2020-07-29T02:32:55.355646Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Seq2Seq(encoderNet, decoderNet).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:55.783682Z",
     "start_time": "2020-07-29T02:32:55.774376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(7854, 300)\n",
       "    (lstm): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(5893, 300)\n",
       "    (lstm): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
       "    (fc): Linear(in_features=1024, out_features=5893, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:32:56.974944Z",
     "start_time": "2020-07-29T02:32:56.968185Z"
    }
   },
   "outputs": [],
   "source": [
    "padIdx = english.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=padIdx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-29T02:48:19.090896Z",
     "start_time": "2020-07-29T02:32:57.240036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 / 20]\n",
      "=> Saving checkpoint\n",
      "['think', 'bloom', 'lettuce', 'lettuce', 'lots', 'outfielder', 'outfielder', 'outfielder', 'mr.', 'lighted', 'sing', 'sing', 'think', 'railroad', 'length', 'vine', 'pineapple', 'pineapple', 'dives', 'dives', 'lap', 'escalators', 'reacting', 'tackle', 'tackle', 'pile', 'travel', 'standing', 'mattress', 'mattress', 'hulk', 'hulk', 'attempt', 'attempt', 'dishes', 'dishes', 'dishes', 'player', 'time', 'enjoy', 'enjoy', 'bmw', 'tourist', 'experiment', 'experiment', 'photographers', 'cherry', 'cherry', 'experiment', 'cherry']\n",
      "[Epoch 2 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'child', 'in', 'a', 'blue', 'shirt', 'is', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 3 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', '<unk>', 'player', 'with', 'a', '<unk>', '<unk>', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 4 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'skier', 'with', 'a', '<unk>', 'is', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '.', '<eos>']\n",
      "[Epoch 5 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', '<unk>', 'with', 'with', 'a', '<unk>', 'is', '<unk>', 'by', 'a', '<unk>', 'of', 'a', '.', '<eos>']\n",
      "[Epoch 6 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'police', 'officer', 'with', 'a', '<unk>', 'is', 'being', 'pulled', 'by', 'a', 'a', 'of', 'a', '.', '<eos>']\n",
      "[Epoch 7 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'large', 'with', 'with', 'a', 'large', 'of', 'of', 'a', 'by', 'a', 'large', '<unk>', '.', '.', '<eos>']\n",
      "[Epoch 8 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'large', 'boat', 'with', 'two', 'men', 'are', 'by', 'a', 'large', 'of', 'a', 'large', 'large', '.', '.', '<eos>']\n",
      "[Epoch 9 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'large', 'boat', 'is', 'pulled', 'by', 'a', 'large', 'of', 'of', 'a', 'large', '.', '.', '<eos>']\n",
      "[Epoch 10 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'a', 'large', 'boat', 'pulled', 'by', 'a', 'large', 'of', 'of', 'large', 'large', '.', '.', '<eos>']\n",
      "[Epoch 11 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'large', 'boat', 'pulled', 'pulled', 'pulled', 'from', 'a', 'large', 'cable', '.', '<eos>']\n",
      "[Epoch 12 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'large', 'number', 'pulled', 'pulled', 'by', 'a', 'large', 'large', 'large', 'large', '.', '<eos>']\n",
      "[Epoch 13 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'large', 'boat', 'pulled', 'pulled', 'behind', 'a', 'large', 'of', 'of', 'large', 'large', '.', '<eos>']\n",
      "[Epoch 14 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'large', 'number', 'pulled', 'pulled', 'pulled', 'by', 'a', 'large', 'cable', 'of', 'two', 'columns', '.', '<eos>']\n",
      "[Epoch 15 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'large', 'boat', 'is', 'being', 'pulled', 'by', 'a', 'large', 'cable', 'of', 'large', '.', '<eos>']\n",
      "[Epoch 16 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'large', 'boat', 'is', 'pulled', 'by', 'a', 'large', 'cable', 'by', 'large', 'large', 'columns', '.', '<eos>']\n",
      "[Epoch 17 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'has', 'a', 'lot', 'of', 'being', 'pulled', 'by', 'a', 'large', 'cable', 'of', 'horses', '.', '<eos>']\n",
      "[Epoch 18 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'the', 'boat', 'is', 'pulled', 'by', 'a', 'large', 'cable', 'by', 'a', 'large', 'cable', '.', '<eos>']\n",
      "[Epoch 19 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'with', 'many', 'men', 'being', 'pulled', 'by', 'a', 'large', 'large', 'by', 'horses', '.', '<eos>']\n",
      "[Epoch 20 / 20]\n",
      "=> Saving checkpoint\n",
      "['a', 'boat', 'with', 'with', 'men', 'being', 'pulled', 'by', 'a', 'large', 'by', 'a', 'large', 'large', '.', '<eos>']\n",
      "Bleu score 19.06\n"
     ]
    }
   ],
   "source": [
    "if loadModel:\n",
    "    load_checkpoint(torch.load('my_checkpoint.pth.tar'), model, optimizer)\n",
    "    \n",
    "sentence = \"ein boot mit mehreren männern darauf wird von einem großen pferdegespann ans ufer gezogen.\"\n",
    "    \n",
    "for epoch in range(numEpochs):\n",
    "    print(f'[Epoch {epoch+1} / {numEpochs}]')\n",
    "    \n",
    "    checkpoint = {'state_dict' : model.state_dict(), 'optimizer' : optimizer.state_dict()}\n",
    "    save_checkpoint(checkpoint)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    translatedSentence = translate_sentence(model, sentence, german, english, device, max_length=50)\n",
    "    \n",
    "    print(translatedSentence)\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batchIdx, batch in enumerate(trainIterator):\n",
    "        inputData = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "        \n",
    "        output = model(inputData, target)\n",
    "        # output shape : (trg len, batch size, output dim)\n",
    "        \n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "        \n",
    "score = bleu(testData[1:100], model, german, english, device)\n",
    "print(f'Bleu score {score*100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
